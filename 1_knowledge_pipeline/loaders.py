# # 1_knowledge_pipeline/loaders.py (Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø¹Ø¯Ù„Ø© ÙˆØ§Ù„ØµØ­ÙŠØ­Ø©)

# import os
# import json
# from typing import List, Tuple, Optional
# from langchain_core.documents import Document

# from langchain_community.document_loaders import (
#     PyPDFLoader,
#     TextLoader,
#     UnstructuredWordDocumentLoader
# )

# LOADER_MAPPING = {
#     ".pdf": PyPDFLoader,
#     ".docx": UnstructuredWordDocumentLoader,
#     ".txt": TextLoader,
# }

# def load_documents(source_dir: str) -> Tuple[List[Document], Optional[str]]:
#     """
#     ÙŠÙ‚ÙˆÙ… Ø¨ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø© Ù…Ø¹ Ø¶Ù…Ø§Ù† Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù†ØµÙŠØ© Ø¨ØªØ±Ù…ÙŠØ² UTF-8.
#     """
#     all_documents = []
#     entity_name = None
#     config_file_path = os.path.join(source_dir, "config.json")

#     print(f"ğŸ“‚ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…Ø³Ø­ ÙˆØ§Ù„ØªØ­Ù…ÙŠÙ„ ÙÙŠ: '{source_dir}'")

#     if not os.path.isdir(source_dir):
#         raise ValueError(f"Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯ Ù„ÙŠØ³ Ù…Ø¬Ù„Ø¯Ù‹Ø§ ØµØ§Ù„Ø­Ù‹Ø§: {source_dir}")

#     if os.path.exists(config_file_path):
#         try:
#             with open(config_file_path, "r", encoding="utf-8") as f:
#                 config_data = json.load(f)
#                 entity_name = config_data.get("entity_name")
#                 if entity_name:
#                     print(f"  - âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù‡ÙˆÙŠØ© Ø§Ù„Ø¹Ù…ÙŠÙ„: '{entity_name}'")
#         except Exception as e:
#             print(f"  - âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© 'config.json': {e}")
#     else:
#         print(f"  - âš ï¸ ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù 'config.json'.")

#     for filename in os.listdir(source_dir):
#         if filename == "config.json" or filename.startswith('.'):
#             continue
        
#         file_path = os.path.join(source_dir, filename)
#         if not os.path.isfile(file_path):
#             continue

#         file_ext = os.path.splitext(filename)[1].lower()
#         if file_ext in LOADER_MAPPING:
#             loader_class = LOADER_MAPPING[file_ext]
#             print(f"  - ğŸ“„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ '{filename}' Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… {loader_class.__name__}...")
#             try:
#                 # --- vvvvvvvvvvvvvvvv Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ vvvvvvvvvvvvvvvv ---
                
#                 # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù Ù†ØµÙŠÙ‹Ø§ØŒ Ø§Ø³ØªØ®Ø¯Ù… ØªØ±Ù…ÙŠØ² UTF-8
#                 if loader_class == TextLoader:
#                     loader = loader_class(file_path, encoding='utf-8')
#                 else:
#                     # Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø®Ø±Ù‰ (PDF, DOCX)ØŒ Ø§Ø³ØªÙ…Ø± ÙƒØ§Ù„Ù…Ø¹ØªØ§Ø¯
#                     loader = loader_class(file_path)
                
#                 # --- ^^^^^^^^^^^^^^^^^^ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ ^^^^^^^^^^^^^^^^^^ ---

#                 loaded_docs = loader.load()
#                 all_documents.extend(loaded_docs)
#                 print(f"    - âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(loaded_docs)} ØµÙØ­Ø©/Ø¬Ø²Ø¡.")
#             except Exception as e:
#                 print(f"    - âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù '{filename}'. Ø§Ù„Ø®Ø·Ø£: {e}")
#         else:
#             print(f"  - â© ØªÙ… ØªØ®Ø·ÙŠ Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…: '{filename}'")

#     if not all_documents:
#         print("\nÙ„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©.")
    
#     print(f"\nâœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„. Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª/Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©: {len(all_documents)}")
#     return all_documents, entity_name
# 1_knowledge_pipeline/loaders.py (Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© - v2.0)

import os
import json
from typing import List, Tuple, Optional
from langchain_core.documents import Document

from langchain_community.document_loaders import (
    PyPDFLoader,
    TextLoader,
    UnstructuredWordDocumentLoader
)

# Ù„Ø§ ØªØºÙŠÙŠØ± Ù‡Ù†Ø§
LOADER_MAPPING = {
    ".pdf": PyPDFLoader,
    ".docx": UnstructuredWordDocumentLoader,
    ".txt": TextLoader,
}

def load_documents_from_source(source_dir: str) -> Tuple[List[Document], Optional[str]]:
    """
    ÙŠÙ‚ÙˆÙ… Ø¨ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ© (ØµÙØ­Ø§Øª/Ø£Ø¬Ø²Ø§Ø¡) Ù…Ù† Ù…Ø¬Ù„Ø¯ Ù…ØµØ¯Ø± Ù…Ø­Ø¯Ø¯.
    Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© Ù‡ÙŠ Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ø£ÙˆÙ„Ù‰ ÙÙ‚Ø·ØŒ ÙˆØ³ÙŠØªÙ… ØªÙ…Ø±ÙŠØ± Ù…Ø®Ø±Ø¬Ø§ØªÙ‡Ø§ Ø¥Ù„Ù‰ Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ‚Ø·ÙŠØ¹ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©.
    """
    all_pages = []
    entity_name = None
    config_file_path = os.path.join(source_dir, "config.json")

    print(f"\n[+] Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ù…Ø³Ø­ ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ù…Ù†: '{source_dir}'")

    if not os.path.isdir(source_dir):
        print(f"  - âŒ Ø®Ø·Ø£: Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯ Ù„ÙŠØ³ Ù…Ø¬Ù„Ø¯Ù‹Ø§ ØµØ§Ù„Ø­Ù‹Ø§: {source_dir}")
        return [], None

    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„ Ù…Ù† config.json
    if os.path.exists(config_file_path):
        try:
            with open(config_file_path, "r", encoding="utf-8") as f:
                config_data = json.load(f)
                entity_name = config_data.get("entity_name")
                if entity_name:
                    print(f"  - âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù‡ÙˆÙŠØ© Ø§Ù„Ø¹Ù…ÙŠÙ„: '{entity_name}'")
        except Exception as e:
            print(f"  - âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© 'config.json': {e}")
    else:
        print(f"  - âš ï¸ ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù 'config.json'.")

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª
    for filename in os.listdir(source_dir):
        if filename == "config.json" or filename.startswith('.'):
            continue
        
        file_path = os.path.join(source_dir, filename)
        if not os.path.isfile(file_path):
            continue

        file_ext = os.path.splitext(filename)[1].lower()
        if file_ext in LOADER_MAPPING:
            loader_class = LOADER_MAPPING[file_ext]
            print(f"  - ğŸ“„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ '{filename}'...")
            try:
                loader_options = {'encoding': 'utf-8'} if loader_class == TextLoader else {}
                loader = loader_class(file_path, **loader_options)
                
                loaded_pages = loader.load()
                
                # Ø¥Ø¶Ø§ÙØ© Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¥Ù„Ù‰ ÙƒÙ„ ØµÙØ­Ø© Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ø§Ù„ØªØªØ¨Ø¹ Ù„Ø§Ø­Ù‚Ù‹Ø§
                for page in loaded_pages:
                    if entity_name:
                        page.metadata['entity_name'] = entity_name

                all_pages.extend(loaded_pages)
                print(f"    - âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(loaded_pages)} ØµÙØ­Ø©/Ø¬Ø²Ø¡.")
            except Exception as e:
                print(f"    - âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù '{filename}'. Ø§Ù„Ø®Ø·Ø£: {e}")
        else:
            print(f"  - â© ØªÙ… ØªØ®Ø·ÙŠ Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…: '{filename}'")

    if not all_pages:
        print("\n[*] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…ØµØ¯Ø±.")
    
    print(f"\n[*] Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„ÙŠ. Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©: {len(all_pages)}")
    return all_pages, entity_name
