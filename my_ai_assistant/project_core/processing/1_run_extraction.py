# project_core/processing/1_run_extraction.py
#ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©ØŒ Ø³ØªØ¬Ø¯ Ù…Ø¬Ù„Ø¯Ù‹Ø§ Ø¬Ø¯ÙŠØ¯Ù‹Ø§ Ø§Ø³Ù…Ù‡ intermediate_outputsØŒ ÙˆØ¨Ø¯Ø§Ø®Ù„Ù‡ Ù…Ù„ÙØ§Øª .json ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„ Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙˆØ§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ©.
import os
import logging
import json
import base64
import io
import zipfile
from datetime import datetime

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©
from unstructured.partition.auto import partition
from unstructured.documents.elements import Table
from pdf2image import convert_from_path
from tqdm import tqdm

from project_core.core.config import DATA_SOURCES_DIR, BASE_DIR

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ---
LOGS_DIR = os.path.join(BASE_DIR, "logs")
if not os.path.exists(LOGS_DIR): os.makedirs(LOGS_DIR)
log_filename = datetime.now().strftime(f"extraction_run_%Y-%m-%d_%H-%M-%S.log")
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(name)s - %(message)s', handlers=[logging.FileHandler(os.path.join(LOGS_DIR, log_filename), encoding='utf-8'), logging.StreamHandler()])
logger = logging.getLogger("extraction_pipeline")

# --- Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„ÙˆØ³ÙŠØ·Ø© ---
INTERMEDIATE_DIR = os.path.join(BASE_DIR, "intermediate_outputs")
if not os.path.exists(INTERMEDIATE_DIR): os.makedirs(INTERMEDIATE_DIR)

def extract_images_from_docx(file_path: str):
    # ... (Ù†ÙØ³ Ø§Ù„Ø¯Ø§Ù„Ø© Ù…Ù† Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚) ...
    images_base64 = []
    try:
        with zipfile.ZipFile(file_path, 'r') as zf:
            image_files = [f for f in zf.namelist() if f.startswith('word/media/')]
            for filename in tqdm(image_files, desc="Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„ØµÙˆØ± Ù…Ù† DOCX"):
                with zf.open(filename) as f:
                    images_base64.append(base64.b64encode(f.read()).decode('utf-8'))
        if images_base64:
            logger.info(f"Ø§Ù„Ø®Ø·Ø© 'Ø¬' Ù†Ø¬Ø­Øª: ØªÙ… Ø§Ø³ØªØ®Ù„Ø§Øµ {len(images_base64)} ØµÙˆØ±Ø© Ù…Ù† DOCX.")
    except Exception as e: logger.error(f"ÙØ´Ù„Øª Ø§Ù„Ø®Ø·Ø© 'Ø¬' Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„ØµÙˆØ± Ù…Ù† DOCX. Ø§Ù„Ø®Ø·Ø£: {e}")
    return images_base64

def run_extraction():
    logger.info("="*50 + "\nðŸš€ Ø¨Ø¯Ø¡ Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ ÙÙ‚Ø·...\n" + "="*50)
    
    for tenant_id in os.listdir(DATA_SOURCES_DIR):
        tenant_path = os.path.join(DATA_SOURCES_DIR, tenant_id)
        if not os.path.isdir(tenant_path): continue
        
        logger.info(f"\n--- Ø§Ù„Ù…Ø³Ø­ Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ø¸Ø§Ù…: [{tenant_id}] ---")
        for file_name in os.listdir(tenant_path):
            file_path = os.path.join(tenant_path, file_name)
            if not os.path.isfile(file_path): continue

            logger.info(f"--- Ø¨Ø¯Ø¡ Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ù…Ù„Ù: {file_name} ---")
            texts, tables_html, images_base64 = [], [], []

            # 1. Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ø¬Ø¯Ø§ÙˆÙ„
            try:
                raw_elements = partition(file_path, strategy="auto", languages=["ara", "eng"])
                for element in raw_elements:
                    if isinstance(element, Table) and hasattr(element.metadata, 'text_as_html'):
                        tables_html.append(element.metadata.text_as_html)
                    elif len(str(element).strip()) > 20:
                        texts.append(str(element))
            except Exception as e:
                logger.error(f"ÙØ´Ù„ Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ù†ØµÙˆØµ/Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ù…Ù† {file_name}. Ø§Ù„Ø®Ø·Ø£: {e}")

            # 2. Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„ØµÙˆØ± Ø¨Ø§Ù„Ø®Ø·Ø· Ø§Ù„Ø¨Ø¯ÙŠÙ„Ø©
            if file_path.lower().endswith(".pdf"):
                try:
                    pil_images = convert_from_path(file_path)
                    for img in tqdm(pil_images, desc="ØªØ­ÙˆÙŠÙ„ ØµÙØ­Ø§Øª PDF Ø¥Ù„Ù‰ ØµÙˆØ±"):
                        buffer = io.BytesIO(); img.save(buffer, format="JPEG")
                        images_base64.append(base64.b64encode(buffer.getvalue()).decode('utf-8'))
                except Exception as e:
                    logger.error(f"ÙØ´Ù„ ØªØ­ÙˆÙŠÙ„ PDF Ø¥Ù„Ù‰ ØµÙˆØ± Ù„Ù€ {file_name}. Ø§Ù„Ø®Ø·Ø£: {e}")
            elif file_path.lower().endswith(".docx"):
                images_base64.extend(extract_images_from_docx(file_path))

            # 3. Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù…Ù„Ù ÙˆØ³ÙŠØ·
            output_data = {
                "source_file": file_name,
                "tenant_id": tenant_id,
                "extracted_texts": texts,
                "extracted_tables_html": tables_html,
                "extracted_images_base64": images_base64
            }
            
            output_filename = f"{tenant_id}_{os.path.splitext(file_name)[0]}.json"
            output_path = os.path.join(INTERMEDIATE_DIR, output_filename)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=4)
                
            logger.info(f"âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ù…Ù„Ù {file_name}. ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ: {output_path}")
            logger.info(f"   > Ù…Ù„Ø®Øµ: {len(texts)} Ù†ØµØŒ {len(tables_html)} Ø¬Ø¯ÙˆÙ„ØŒ {len(images_base64)} ØµÙˆØ±Ø©.")

if __name__ == "__main__":
    run_extraction()
