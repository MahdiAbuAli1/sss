# # ุงููุณุงุฑ: 2_central_api_service/agent_app/advanced_tester.py
# # --- ุงููุณุฎุฉ ูุงุฆูุฉ ุงูุณุฑุนุฉ (ูุน ูุญุงูุงุฉ ุฅุนุงุฏุฉ ุตูุงุบุฉ ุงูุณุคุงู) ---

# import asyncio
# import os
# from typing import List, Tuple
# from dotenv import load_dotenv

# # --- ุงุณุชูุฑุงุฏ ููููุงุช LangChain (ูุง ุชุบููุฑ) ---
# from langchain_core.documents import Document
# from langchain_community.embeddings import OllamaEmbeddings
# from langchain_community.vectorstores import FAISS
# from langchain.retrievers import BM25Retriever, EnsembleRetriever

# # --- ุงูุฅุนุฏุงุฏุงุช ุงูุฃุณุงุณูุฉ (ูุง ุชุบููุฑ) ---
# PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../"))
# load_dotenv(dotenv_path=os.path.join(PROJECT_ROOT, ".env"))
# EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL_NAME", "qwen3-embedding:0.6b")
# UNIFIED_DB_PATH = os.path.join(PROJECT_ROOT, "3_shared_resources", "vector_db")

# # --- ุฏูุงู ูุณุงุนุฏุฉ (ูุง ุชุบููุฑ) ---
# def _load_all_docs_from_faiss(vector_store: FAISS) -> List[Document]:
#     return list(vector_store.docstore._dict.values())

# def print_results(docs: List[Document], title: str):
#     print(f"\n--- {title} ---")
#     if not docs:
#         print("   -> ูู ูุชู ุงูุนุซูุฑ ุนูู ูุชุงุฆุฌ.")
#         return
#     print(f"   -> ุนุฏุฏ ุงููุชุงุฆุฌ: {len(docs)}")
#     for i, doc in enumerate(docs):
#         source = doc.metadata.get('source', 'ุบูุฑ ูุนุฑูู').split('\\')[-1]
#         tenant = doc.metadata.get('tenant_id', 'N/A')
#         content_preview = ' '.join(doc.page_content.replace('\n', ' ').split())[:100]
#         print(f"   {i+1}. [ุงูุนููู: {tenant}, ุงููุตุฏุฑ: {source}] -> \"{content_preview}...\"")
#     print("-" * (len(title) + 6))

# # --- ุชููุฆุฉ ุงูุจูุฆุฉ (ุชุนุฏูู ุจุณูุท ูุฅุฒุงูุฉ LLM ุบูุฑ ุงูุถุฑูุฑู ุงูุขู) ---
# async def setup_environment() -> FAISS:
#     print("--- ๐ฌ ุจุฏุก ุชููุฆุฉ ุจูุฆุฉ ุงูุงุฎุชุจุงุฑ (ููุงุณุชุฑุฌุงุน ููุท) ๐ฌ ---")
#     embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL, base_url=os.getenv("OLLAMA_HOST"))
#     if not os.path.isdir(UNIFIED_DB_PATH):
#         raise FileNotFoundError("ูุงุนุฏุฉ ุงูุจูุงูุงุช ุงููุชุฌูุฉ ุบูุฑ ููุฌูุฏุฉ.")
#     faiss_vector_store = await asyncio.to_thread(
#         FAISS.load_local, UNIFIED_DB_PATH, embeddings, allow_dangerous_deserialization=True
#     )
#     print("--- โจ ุจูุฆุฉ ุงูุงุฎุชุจุงุฑ ุฌุงูุฒุฉ (FAISS store) โจ ---\n")
#     return faiss_vector_store

# # --- ุชุฌุฑุจุฉ ุงููุฑุญูุฉ ุงูุซุงููุฉ (ุจุดูู ูุญุงูู ูุณุฑูุน) ---

# async def experiment_2_1_simulated_query_rewriting(vector_store: FAISS, question: str, tenant_id: str):
#     """
#     ุงูุชุฌุฑุจุฉ 2.1 (ูุญุงูุงุฉ): ุงุฎุชุจุงุฑ ุชุฃุซูุฑ ุฅุนุงุฏุฉ ุตูุงุบุฉ ุงูุณุคุงู ุจุฏูู ุงูุชุธุงุฑ LLM.
#     """
#     print("\n" + "="*60)
#     print(f"๐ฌ ุงูุชุฌุฑุจุฉ 2.1 (ูุญุงูุงุฉ): ุงูุณุคุงู: '{question}' ููุนููู '{tenant_id}'")
#     print("="*60)

#     # ุจูุงุก ุงููุณุชุฑุฌุน ุงููุฌูู ุงููููุชุฑ (ููุณ ุงูููุทู ุงูุณุงุจู)
#     all_docs = _load_all_docs_from_faiss(vector_store)
#     tenant_docs = [doc for doc in all_docs if doc.metadata.get("tenant_id") == tenant_id]
#     if not tenant_docs:
#         print(f"โ ูุง ุชูุฌุฏ ูุณุชูุฏุงุช ููุนููู '{tenant_id}'.")
#         return
    
#     bm25_retriever = BM25Retriever.from_documents(tenant_docs)
#     bm25_retriever.k = 5
#     faiss_retriever = vector_store.as_retriever(
#         search_kwargs={'k': 5, 'filter': {'tenant_id': tenant_id}}
#     )
#     ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5])

#     # ุงูุจุญุซ ุจุงูุณุคุงู ุงูุฃุตูู
#     original_docs = await ensemble_retriever.ainvoke(question)
#     print_results(original_docs, "1. ุงููุชุงุฆุฌ ุจุงูุณุคุงู ุงูุฃุตูู (ุงูุบุงูุถ)")

#     # *** ุงููุญุงูุงุฉ ุงูุฐููุฉ (ุงูุบุด) ***
#     # ุจุฏูุงู ูู ุงูุชุธุงุฑ LLMุ ุณููุชุจ ุจุฃููุณูุง ุงูุณุคุงู ุงูุฐู ูุชููุน ุฃู ูููุฏู
#     print("\n๐ง ูุญุงูุงุฉ ูู LLM: ูููู ุจุฅุนุงุฏุฉ ุตูุงุบุฉ ุงูุณุคุงู ูุฏูููุง...")
#     simulated_rewritten_query = "ุงููุชุทูุจุงุช ุงููุธูููุฉ ูุบูุฑ ุงููุธูููุฉ ูุชุทุจูู ุงููุณุชุฎุฏู ูุงููุฏูุฑ"
#     print(f"โจ ุงูุณุคุงู ุงูููุนุงุฏ ุตูุงุบุชู (ุงููุญุงูู): '{simulated_rewritten_query}'")

#     # ุงูุจุญุซ ุจุงูุณุคุงู ุงููุญุงูู
#     rewritten_docs = await ensemble_retriever.ainvoke(simulated_rewritten_query)
#     print_results(rewritten_docs, "2. ุงููุชุงุฆุฌ ุจุงูุณุคุงู ุงูููุนุงุฏ ุตูุงุบุชู (ุงููุญุงูู)")

# # --- ุงูุฏุงูุฉ ุงูุฑุฆูุณูุฉ ---

# async def main():
#     vector_store = await setup_environment()
    
#     failed_question = "ูุง ูู ููููุงุช ูุธุงู ุงูุนูููุ"
#     target_tenant = "university_alpha"
    
#     await experiment_2_1_simulated_query_rewriting(vector_store, question=failed_question, tenant_id=target_tenant)

# if __name__ == "__main__":
#     asyncio.run(main())


# ุงููุณุงุฑ: 2_central_api_service/agent_app/advanced_tester.py
# --- ุงููุณุฎุฉ ุงููุญุฏุซุฉ ูุน ุงูุชุฌุฑุจุฉ 2.2: ุงูุชูุฌูู ุงููุฎุตุต ---

import asyncio
import os
from typing import List, Tuple
from dotenv import load_dotenv

# --- ุงุณุชูุฑุงุฏ ููููุงุช LangChain (ูุง ุชุบููุฑ) ---
from langchain_core.documents import Document
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.retrievers import BM25Retriever, EnsembleRetriever

# --- ุงูุฅุนุฏุงุฏุงุช ุงูุฃุณุงุณูุฉ (ูุง ุชุบููุฑ) ---
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../"))
load_dotenv(dotenv_path=os.path.join(PROJECT_ROOT, ".env"))
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL_NAME", "qwen3-embedding:0.6b")
UNIFIED_DB_PATH = os.path.join(PROJECT_ROOT, "3_shared_resources", "vector_db")

# --- ุฏูุงู ูุณุงุนุฏุฉ (ูุง ุชุบููุฑ) ---
def _load_all_docs_from_faiss(vector_store: FAISS) -> List[Document]:
    return list(vector_store.docstore._dict.values())

def print_results(docs: List[Document], title: str):
    print(f"\n--- {title} ---")
    if not docs:
        print("   -> ูู ูุชู ุงูุนุซูุฑ ุนูู ูุชุงุฆุฌ.")
        return
    print(f"   -> ุนุฏุฏ ุงููุชุงุฆุฌ: {len(docs)}")
    for i, doc in enumerate(docs):
        source = doc.metadata.get('source', 'ุบูุฑ ูุนุฑูู').split('\\')[-1]
        tenant = doc.metadata.get('tenant_id', 'N/A')
        content_preview = ' '.join(doc.page_content.replace('\n', ' ').split())[:100]
        print(f"   {i+1}. [ุงูุนููู: {tenant}, ุงููุตุฏุฑ: {source}] -> \"{content_preview}...\"")
    print("-" * (len(title) + 6))

# --- ุชููุฆุฉ ุงูุจูุฆุฉ (ูุง ุชุบููุฑ) ---
async def setup_environment() -> FAISS:
    print("--- ๐ฌ ุจุฏุก ุชููุฆุฉ ุจูุฆุฉ ุงูุงุฎุชุจุงุฑ (ููุงุณุชุฑุฌุงุน ููุท) ๐ฌ ---")
    embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL, base_url=os.getenv("OLLAMA_HOST"))
    if not os.path.isdir(UNIFIED_DB_PATH):
        raise FileNotFoundError("ูุงุนุฏุฉ ุงูุจูุงูุงุช ุงููุชุฌูุฉ ุบูุฑ ููุฌูุฏุฉ.")
    faiss_vector_store = await asyncio.to_thread(
        FAISS.load_local, UNIFIED_DB_PATH, embeddings, allow_dangerous_deserialization=True
    )
    print("--- โจ ุจูุฆุฉ ุงูุงุฎุชุจุงุฑ ุฌุงูุฒุฉ (FAISS store) โจ ---\n")
    return faiss_vector_store

# --- ุชุฌุฑุจุฉ ุงููุฑุญูุฉ 2.2: ุงูุชูุฌูู ุงููุฎุตุต (ูุญุงูุงุฉ) ---

async def experiment_2_2_context_aware_rewriting(vector_store: FAISS, question: str, tenant_id: str):
    """
    ุงูุชุฌุฑุจุฉ 2.2 (ูุญุงูุงุฉ): ุงุฎุชุจุงุฑ ุชุฃุซูุฑ ุฅุนุทุงุก ุงููููุฐุฌ "ููู ุดุฎุตู ูููุธุงู" ูุจู ุฅุนุงุฏุฉ ุงูุตูุงุบุฉ.
    """
    print("\n" + "="*60)
    print(f"๐ฌ ุงูุชุฌุฑุจุฉ 2.2 (ูุญุงูุงุฉ): ุงูุณุคุงู: '{question}' ููุนููู '{tenant_id}'")
    print("="*60)

    # --- ูุญุงูุงุฉ "ุงูููู ุงูุดุฎุตู ูููุธุงู" ---
    # ูู ูุธุงู ุญููููุ ุณูุชู ุชุญููู ูุฐู ุงูุจูุงูุงุช ูู ููู config.json ุฃู ูุงุนุฏุฉ ุจูุงูุงุช
    system_profiles = {
        "sys": {
            "name": "ูุธุงู ุฅุฏุงุฑุฉ ุทูุจุงุช ุงูุงุนุชูุงุฏ",
            "description": "ูุธุงู ูุชุชุจุน ูุฑุงุญู ุงูุญุตูู ุนูู ุงูุงุนุชูุงุฏ ูู ุงูุชูุฏูู ุญุชู ุฅุตุฏุงุฑ ุงูุดูุงุฏุฉ.",
            "keywords": ["ุทูุจ ุงุนุชูุงุฏ", "ููุงุฆู ุงูุชุญูู", "ุฏุฑุงุณุฉ ููุชุจูุฉ", "ุฒูุงุฑุฉ ููุฏุงููุฉ", "ุฅุฌุฑุงุกุงุช ุชุตุญูุญูุฉ"]
        },
        "university_alpha": {
            "name": "ุชุทุจูู Plant Care",
            "description": "ุชุทุจูู ุฐูู ููุณุงุนุฏุฉ ุงููุฒุงุฑุนูู ูู ุงูุชุนุฑู ุนูู ุงูุขูุงุช ุงูุฒุฑุงุนูุฉ.",
            "keywords": ["ูุชุทูุจุงุช ูุธูููุฉ", "ุญุงูุงุช ุงุณุชุฎุฏุงู", "ุชุตููู ุงููุธุงู", "ูุฎุทุท ุนูุงูุงุช", "plant care"]
        }
    }
    
    profile = system_profiles.get(tenant_id)
    if not profile:
        print(f"โ ูุง ููุฌุฏ ููู ุดุฎุตู ููุนููู '{tenant_id}'.")
        return

    print(f"๐ค ุชู ุงูุนุซูุฑ ุนูู ููู ุดุฎุตู ูู '{profile['name']}'")

    # ุจูุงุก ุงููุณุชุฑุฌุน ุงููุฌูู ุงููููุชุฑ (ููุณ ุงูููุทู ุงูุณุงุจู)
    all_docs = _load_all_docs_from_faiss(vector_store)
    tenant_docs = [doc for doc in all_docs if doc.metadata.get("tenant_id") == tenant_id]
    bm25_retriever = BM25Retriever.from_documents(tenant_docs)
    bm25_retriever.k = 5
    faiss_retriever = vector_store.as_retriever(search_kwargs={'k': 5, 'filter': {'tenant_id': tenant_id}})
    ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5])

    # *** ุงููุญุงูุงุฉ ุงูุฐููุฉ (ุจุงุณุชุฎุฏุงู ุงูููู ุงูุดุฎุตู) ***
    print("\n๐ง ูุญุงูุงุฉ ูู LLM (ูุน ุณูุงู ุงููุธุงู): ูููู ุจุตูุงุบุฉ ุณุคุงู ุฃูุถู ูุฏูููุง...")
    
    # ูุซุงู ุนูู ููููุฉ ุงุณุชุฎุฏุงู ุงูููู ุงูุดุฎุตู ูุชูููุฏ ุณุคุงู ุฃูุถู
    # ุณูุฎุชุงุฑ ูููุฉ ููุชุงุญูุฉ ูู ุงูููู ุงูุดุฎุตู ููุจุญุซ ุนููุง
    simulated_rewritten_query = f"ุฎุทูุงุช {profile['keywords'][0]}"
    
    print(f"โจ ุงูุณุคุงู ุงูุฃุตูู: '{question}'")
    print(f"โจ ุงูุณุคุงู ุงูููุนุงุฏ ุตูุงุบุชู (ุงููุญุงูู): '{simulated_rewritten_query}'")

    # ุงูุจุญุซ ุจุงูุณุคุงู ุงููุญุงูู
    rewritten_docs = await ensemble_retriever.ainvoke(simulated_rewritten_query)
    print_results(rewritten_docs, f"ุงููุชุงุฆุฌ ุจุงุณุชุฎุฏุงู ุงูุณุคุงู ุงููุญุงูู ูุงููุฎุตุต ููุธุงู '{profile['name']}'")

# --- ุงูุฏุงูุฉ ุงูุฑุฆูุณูุฉ ---

async def main():
    vector_store = await setup_environment()
    
    # --- ุชุดุบูู ุงูุชุฌุฑุจุฉ 2.2 ุนูู ูุธุงู ุงูุงุนุชูุงุฏ ---
    # ุณุคุงู ุนุงู ุฌุฏูุง
    generic_question = "ููู ุฃุจุฏุฃุ"
    target_tenant_sys = "sys"
    
    await experiment_2_2_context_aware_rewriting(vector_store, question=generic_question, tenant_id=target_tenant_sys)

if __name__ == "__main__":
    asyncio.run(main())
