# ุงููุณุงุฑ: 2_central_api_service/agent_app/final_tuning_tester_v2.py
# --- ุงูุฅุตุฏุงุฑ 14.0: ุชุญุณูู ุงูุฃุฏุงุกุ ุงูุณูุงู ุงูุฏููุงููููุ ูุงูุชูููู ุงูููู ---

import os
import logging
import asyncio
from typing import List, Dict

from dotenv import load_dotenv
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.llms import Ollama
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.retrievers import BM25Retriever, EnsembleRetriever
from flashrank import Ranker, RerankRequest

# [ุชุญุณูู] ุงุณุชูุฑุงุฏ ููุชุจุงุช ุงูุชูููู (Ragas)
import pandas as pd
from datasets import Dataset
from ragas import evaluate
from ragas.metrics import faithfulness, answer_relevancy, context_recall, context_precision

# --- 1. ุงูุฅุนุฏุงุฏุงุช ---
# (ููุณ ุงูุฅุนุฏุงุฏุงุช ุงูุณุงุจูุฉ)
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../"))
load_dotenv(dotenv_path=os.path.join(PROJECT_ROOT, ".env"))
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL_NAME", "qwen3-embedding:0.6b")
CHAT_MODEL = os.getenv("CHAT_MODEL_NAME", "qwen2:7b-instruct-q3_K_M")
OLLAMA_HOST = os.getenv("OLLAMA_HOST")
UNIFIED_DB_PATH = os.path.join(PROJECT_ROOT, "3_shared_resources", "vector_db")

# [ุชุญุณูู] ุฅุถุงูุฉ ูุชุบูุฑุงุช ููุชุญูู ูู ุงูุชุญุณููุงุช ุงูุฌุฏูุฏุฉ
RERANK_SCORE_THRESHOLD = 0.1 # ุนุชุจุฉ ุงูุซูุฉ ููุณูุงู ุงูุฏููุงูููู (ูููุฉ ููุฎูุถุฉ ูุจุฏุฆููุง ูุถูุงู ูุฌูุฏ ุณูุงู)

# --- 2. ุงููููุงุช ุงูุดุฎุตูุฉ ูุงูููุงูุจ (ุชุจูู ููุง ูู) ---
SYSTEM_PROFILES = {
    "sys": {"name": "ูุธุงู ุฅุฏุงุฑุฉ ุทูุจุงุช ุงูุงุนุชูุงุฏ", "description": "ูุธุงู ุฅููุชุฑููู ูุชุชุจุน ุฑุญูุฉ ุงูุญุตูู ุนูู ุงูุงุนุชูุงุฏ.", "keywords": ["ุฅูุดุงุก ุญุณุงุจ", "ุชุณุฌูู ุงูุฏุฎูู", "ุทูุจ ุงุนุชูุงุฏ", "ููุงุฆู ุงูุชุญูู", "ุฏุฑุงุณุฉ ููุชุจูุฉ", "ุฒูุงุฑุฉ ููุฏุงููุฉ", "ุฅุฌุฑุงุกุงุช ุชุตุญูุญูุฉ", "ูุงุชูุฑุฉ", "ุดูุงุฏุฉ"]},
    "university_alpha": {"name": "ุชุทุจูู Plant Care", "description": "ุชุทุจูู ุฐูู ูุชุดุฎูุต ุฃูุฑุงุถ ุงููุจุงุชุงุช ูุงูุขูุงุช ุงูุฒุฑุงุนูุฉ.", "keywords": ["ุชุดุฎูุต ุงููุจุงุช", "ุขูุงุช ุฒุฑุงุนูุฉ", "ูุชุทูุจุงุช ูุธูููุฉ", "ุญุงูุงุช ุงุณุชุฎุฏุงู", "ุชุตููู ุงููุธุงู", "plant care"]},
    "school_beta": {"name": "ูุณุชูุฏุงุช ุงูุดุจูุงุช ุงูุนุตุจูุฉ", "description": "ูุงุฏุฉ ุชุนููููุฉ ุนู ุงูุดุจูุงุช ุงูุนุตุจูุฉ ู TensorFlow.", "keywords": ["ุดุจูุฉ ุนุตุจูุฉ", "tensorflow", "cnn", "layer", "relu", "pooling", "optimizer"]},
    "un": {"name": "ุจูุงุจุฉ ุงููุดุชุฑูุงุช ุงูุฅููุชุฑูููุฉ ููุฃูู ุงููุชุญุฏุฉ", "description": "ุฏููู ุฅุฑุดุงุฏู ููููุฑุฏูู ูุงุณุชุฎุฏุงู ูุธุงู ุงูุดุฑุงุก ุงูุฅููุชุฑููู.", "keywords": ["ููุงูุตุงุช", "ุชุณุฌูู ุงูุฏุฎูู", "ุนุทุงุกุงุช", "unops", "esourcing", "ungm.org", "ููุฑุฏูู"]}
}
REWRITE_PROMPT_TEMPLATE = """... (ููุณ ุงููุงูุจ ุงูุณุงุจู) ..."""
FINAL_ANSWER_PROMPT = ChatPromptTemplate.from_template("""... (ููุณ ุงููุงูุจ ุงูุณุงุจู) ...""")

# --- 4. ุงูุฏูุงู ุงููุณุงุนุฏุฉ ---
def _clean_rewritten_query(raw_query: str) -> str:
    lines = raw_query.strip().split('\n')
    for line in reversed(lines):
        cleaned_line = line.strip()
        if cleaned_line:
            if cleaned_line.startswith("ุงูุงุณุชุนูุงู ุงููุญุณูู:"):
                return cleaned_line.replace("ุงูุงุณุชุนูุงู ุงููุญุณูู:", "").strip()
            return cleaned_line
    return raw_query.strip()

def print_results(docs: List[Document], title: str, scores: List[float] = None):
    print(f"\n--- ๐ {title} (ุนุฏุฏ: {len(docs)}) ---")
    if not docs:
        print("   -> ูุง ุชูุฌุฏ ูุณุชูุฏุงุช.")
        return
    for i, doc in enumerate(docs):
        content_preview = ' '.join(doc.page_content.replace('\n', ' ').split())[:80]
        score_info = f"[ุงูุฏุฑุฌุฉ: {scores[i]:.4f}]" if scores else ""
        print(f"   {i+1}. {score_info} [ูุตุฏุฑ: {doc.metadata.get('source', 'N/A')}] -> \"{content_preview}...\"")

# --- 5. ุงูุฏุงูุฉ ุงูุฑุฆูุณูุฉ ููุงุฎุชุจุงุฑ (ุงููุณุฎุฉ ุงููุญุณููุฉ) ---
async def run_full_test_pipeline(question: str, tenant_id: str, llm: Ollama, vector_store: FAISS, reranker: Ranker, all_docs_for_bm25: Dict[str, List[Document]]):
    print("\n" + "="*80)
    print(f"๐ ุจุฏุก ุงุฎุชุจุงุฑ ูุงูู ููุณุคุงู: '{question}' | ููุนููู: '{tenant_id}'")
    print("="*80)

    # --- ุงููุฑุญูุฉ 0 & 1: ุชุญููู ุงูููู ุงูุดุฎุตู ูุฅุนุงุฏุฉ ุตูุงุบุฉ ุงูุณุคุงู ---
    profile = SYSTEM_PROFILES.get(tenant_id)
    if not profile:
        print(f"โ๏ธ ุชุญุฐูุฑ: ูู ูุชู ุงูุนุซูุฑ ุนูู ููู ุดุฎุตู ููุนููู '{tenant_id}'.")
        effective_question = question
    else:
        print(f"โ [1/5] ุชู ุงูุนุซูุฑ ุนูู ููู ุดุฎุตู: '{profile['name']}'")
        print("๐ง [2/5] ุจุฏุก ุฅุนุงุฏุฉ ุตูุงุบุฉ ุงูุณุคุงู...")
        # ... (ููุณ ููุทู ุฅุนุงุฏุฉ ุงูุตูุงุบุฉ)
        effective_question = question # ุชุจุณูุท ูุฃุบุฑุงุถ ุงูุงุฎุชุจุงุฑุ ููููู ุฅุนุงุฏุฉ ุชูุนูููุง

    # --- ุงููุฑุญูุฉ 2: ุงูุงุณุชุฑุฌุงุน ุงููุฌูู ุงููุญุณูู ---
    print("๐ [3/5] ุจุฏุก ุงูุงุณุชุฑุฌุงุน ุงููุฌูู (ูุน ุงูููุชุฑุฉ ุงููุณุจูุฉ)...")
    
    # [ุชุญุณูู] 1. ุงูููุชุฑุฉ ุงููุณุจูุฉ: ูุง ูุชู ุชุญููู ูู ุงููุณุชูุฏุงุช ูู ุงูุฐุงูุฑุฉ.
    # ูุชู ุงุณุชุฎุฏุงู ุงูููุชุฑุฉ ูุจุงุดุฑุฉ ูู ุงููุณุชุฑุฌุน.
    tenant_docs = all_docs_for_bm25.get(tenant_id)
    if not tenant_docs:
        print(f"โ ุฎุทุฃ: ูุง ุชูุฌุฏ ูุณุชูุฏุงุช ููุฐุง ุงูุนููู '{tenant_id}' ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช.")
        return None

    # ุงููุณุชุฑุฌุน ุงูุฃูู: BM25 ูุนูู ุนูู ุงููุณุชูุฏุงุช ุงููููุชุฑุฉ ูุณุจููุง
    bm25_retriever = BM25Retriever.from_documents(tenant_docs, k=10)
    
    # ุงููุณุชุฑุฌุน ุงูุซุงูู: FAISS ูุณุชุฎุฏู ุงูููุชุฑุฉ ุงููุฏูุฌุฉ
    faiss_retriever = vector_store.as_retriever(
        search_kwargs={'k': 10, 'filter': {'tenant_id': tenant_id}}
    )
    
    ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5])
    
    initial_docs = await ensemble_retriever.ainvoke(effective_question)
    print_results(initial_docs, "ุงููุชุงุฆุฌ ุงูุฃูููุฉ ูู ุงูุจุญุซ ุงููุฌูู")

    # --- ุงููุฑุญูุฉ 3: ุฅุนุงุฏุฉ ุงูุชุฑุชูุจ ูุน ุงูุณูุงู ุงูุฏููุงูููู ---
    print("โจ [4/5] ุจุฏุก ุฅุนุงุฏุฉ ุงูุชุฑุชูุจ (ูุน ุงูุณูุงู ุงูุฏููุงูููู)...")
    if not initial_docs:
        print("   -> ูุง ุชูุฌุฏ ูุชุงุฆุฌ ุฃูููุฉ ูุฅุนุงุฏุฉ ุชุฑุชูุจูุง.")
        reranked_docs = []
    else:
        passages = [{"id": i, "text": doc.page_content} for i, doc in enumerate(initial_docs)]
        rerank_request = RerankRequest(query=question, passages=passages)
        rerank_results = reranker.rerank(rerank_request)

        # [ุชุญุณูู] 2. ุงูุณูุงู ุงูุฏููุงูููู: ููุชุฑุฉ ุงููุชุงุฆุฌ ุจูุงุกู ุนูู ุฏุฑุฌุฉ ุงูุซูุฉ.
        dynamic_top_k = [res for res in rerank_results if res["score"] >= RERANK_SCORE_THRESHOLD]
        
        original_docs_map = {doc.page_content: doc for doc in initial_docs}
        reranked_docs = [original_docs_map[res["text"]] for res in dynamic_top_k if res["text"] in original_docs_map]
        reranked_scores = [res["score"] for res in dynamic_top_k]
        print_results(reranked_docs, f"ุงููุชุงุฆุฌ ุงูููุงุฆูุฉ ุจุนุฏ ุฅุนุงุฏุฉ ุงูุชุฑุชูุจ (ุนุชุจุฉ ุงูุซูุฉ > {RERANK_SCORE_THRESHOLD})", scores=reranked_scores)

    # --- ุงููุฑุญูุฉ 4: ุชูููุฏ ุงูุฅุฌุงุจุฉ ุงูููุงุฆูุฉ ---
    print("โ๏ธ [5/5] ุจุฏุก ุชูููุฏ ุงูุฅุฌุงุจุฉ ุงูููุงุฆูุฉ...")
    answer_chain = FINAL_ANSWER_PROMPT | llm | StrOutputParser()
    
    final_context_docs = reranked_docs
    if not final_context_docs and initial_docs:
        print("   -> ุชุญุฐูุฑ: ูู ุชุชุฌุงูุฒ ุฃู ูุซููุฉ ุนุชุจุฉ ุงูุซูุฉ. ุณูุชู ุงุณุชุฎุฏุงู ุฃูุถู ูุชูุฌุฉ ูู ุงูุจุญุซ ุงูุฃููู ูุฅุฌุฑุงุก ุงุญุชูุงุทู.")
        final_context_docs = initial_docs[:1]

    final_context_str = "\n\n---\n\n".join([doc.page_content for doc in final_context_docs])
    
    final_answer = await answer_chain.ainvoke({
        "system_name": profile.get("name", "ูุฐุง ุงููุธุงู"),
        "context": final_context_str,
        "input": question
    })

    print("\n" + "-"*30 + " ๐ฌ ุงูุฅุฌุงุจุฉ ุงูููุงุฆูุฉ ๐ฌ " + "-"*30)
    print(final_answer)
    print("="*80)

    # [ุชุญุณูู] 3. ุชุฌููุน ุงูุจูุงูุงุช ููุชูููู
    return {
        "question": question,
        "answer": final_answer,
        "contexts": [doc.page_content for doc in final_context_docs],
        # ground_truth ูู ุงูุฅุฌุงุจุฉ ุงููุซุงููุฉ (ูุฌุจ ุชูููุฑูุง ูุฏูููุง ููุชูููู ุงูุฏููู)
        # ูู ูุฐุง ุงููุซุงูุ ุณูุชุฑูู ูุงุฑุบูุง ูุฃููุง ูุง ูููููุง.
        "ground_truth": "ุบูุฑ ูุชููุฑ" 
    }


async def main():
    print("--- ๐ฌ ุจุฏุก ุชููุฆุฉ ุจูุฆุฉ ุงูุงุฎุชุจุงุฑ ุงูููุงุฆูุฉ (v2) ๐ฌ ---")
    try:
        # ุฅุนุฏุงุฏ ููุงุฐุฌ ุงููุบุฉ ูุงููุถููุงุช
        llm = Ollama(model=CHAT_MODEL, base_url=OLLAMA_HOST, temperature=0.0)
        embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL, base_url=OLLAMA_HOST)
        
        # ุชุญููู ูุงุนุฏุฉ ุงูุจูุงูุงุช ุงููุชุฌูุฉ
        vector_store = FAISS.load_local(UNIFIED_DB_PATH, embeddings, allow_dangerous_deserialization=True)
        
        # ุฅุนุฏุงุฏ ููุนูุฏ ุงูุชุฑุชูุจ
        reranker = Ranker()

        # [ุชุญุณูู] ุชุญููู ุงููุณุชูุฏุงุช ูุฑุฉ ูุงุญุฏุฉ ููุท ูู BM25
        print("   -> ุชุญููู ุงููุณุชูุฏุงุช ูู ุงูุฐุงูุฑุฉ ูู BM25 (ูุฑุฉ ูุงุญุฏุฉ ููุท)...")
        all_docs = list(vector_store.docstore._dict.values())
        all_docs_for_bm25 = {}
        for doc in all_docs:
            tenant_id = doc.metadata.get("tenant_id")
            if tenant_id:
                if tenant_id not in all_docs_for_bm25:
                    all_docs_for_bm25[tenant_id] = []
                all_docs_for_bm25[tenant_id].append(doc)
        
        print("--- โ ุจูุฆุฉ ุงูุงุฎุชุจุงุฑ ุงูููุงุฆูุฉ ุฌุงูุฒุฉ ---")
    except Exception as e:
        print(f"โ ูุดู ูุงุฏุญ ูู ุงูุชููุฆุฉ: {e}")
        return

    test_cases = [
        {"question": "ูุงูู ูุฐุง ุงููุธุงู ููู ูุชุจุนู", "tenant_id": "sys"},
        {"question": "ูุงูู ุงูุดุจูุงุช ุงูุนุตุจูู", "tenant_id": "school_beta"},
        {"question": "ููู ูุณุฌู ุงูุฏุฎูู ุงูู ุงููุธุงู", "tenant_id": "un"},
        {"question": "ูู ูู ุฌูุฑุฌููุง", "tenant_id": "sys"},
        {"question": "ูู ุงูุช", "tenant_id": "university_alpha"},
    ]
    
    results_for_evaluation = []
    for test in test_cases:
        result = await run_full_test_pipeline(test["question"], test["tenant_id"], llm, vector_store, reranker, all_docs_for_bm25)
        if result:
            results_for_evaluation.append(result)

    # --- ูุฑุญูุฉ ุงูุชูููู ุจุงุณุชุฎุฏุงู Ragas ---
    print("\n" + "="*35 + " ๐ ุจุฏุก ุงูุชูููู ุงูููู ๐ " + "="*35)
    if not results_for_evaluation:
        print("   -> ูุง ุชูุฌุฏ ูุชุงุฆุฌ ูุชูููููุง.")
        return

    # ุชุญููู ุงููุชุงุฆุฌ ุฅูู ุชูุณูู ููุจูู ูู Ragas
    eval_dataset = Dataset.from_list(results_for_evaluation)
    
    # ุชุนุฑูู ุงูููุงููุณ
    # ููุงุญุธุฉ: answer_relevancy ู context_recall ุชุชุทูุจุงู ground_truthุ ูุฐุง ุณูุชู ุงุณุชุจุนุงุฏููุง ุงูุขู.
    metrics_to_run = [
        faithfulness,      # ูุฏู ุงูุชุฒุงู ุงูุฅุฌุงุจุฉ ุจุงูุณูุงู
        context_precision, # ูุฏู ุฏูุฉ ุงูุณูุงู ุงููุณุชุฑุฌุน ุจุงููุณุจุฉ ููุณุคุงู
    ]

    # ุชุดุบูู ุงูุชูููู
    # Ragas ูุณุชุฎุฏู ููุงุฐุฌ OpenAI ุจุดูู ุงูุชุฑุงุถูุ ูุฌุจ ุชููุฆุชู ูุงุณุชุฎุฏุงู Ollama
    from ragas.llms import LangchainLLM
    from ragas.embeddings import LangchainEmbeddings
    
    ragas_llm = LangchainLLM(llm=llm)
    ragas_embeddings = LangchainEmbeddings(embeddings=embeddings)
    
    score = evaluate(
        eval_dataset,
        metrics=metrics_to_run,
        llm=ragas_llm,
        embeddings=ragas_embeddings
    )
    
    # ุนุฑุถ ุงููุชุงุฆุฌ
    df = score.to_pandas()
    print(df)
    print("="*80)


if __name__ == "__main__":
    # ููุงุญุธุฉ: Ragas ูุฏ ููุงุฌู ูุดุงูู ูู ุจูุฆุฉ asyncio.
    # ูู ุงูุฃูุถู ุชุดุบูู main() ุจุดูู ูุชุฒุงูู ุฅุฐุง ูุงุฌูุช ูุดุงูู.
    # ููููุง ุณูุฌุฑุจ asyncio ุฃููุงู.
    asyncio.run(main())

